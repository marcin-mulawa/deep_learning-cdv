{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porównanie klasyfikatora konwolucyjnego i rekurencyjnego dla NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym notebooku porównamy działanie (architekturę, złożoność, efektywność uczenia) dwóch klasyfikatorów sentymentu recenzji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Załadujmy zależności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding\n",
    "from tensorflow.keras.layers import SpatialDropout1D, Conv1D, GlobalMaxPooling1D, SimpleRNN\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ustawmy hiperparametry dla klasyfikatora konwolucyjnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lokalizacja wyjściowa dla wag:\n",
    "conv_output_dir = 'model_output/conv'\n",
    "\n",
    "# parametry treningu:\n",
    "conv_epochs = 4\n",
    "conv_batch_size = 128\n",
    "\n",
    "# osadzenie przestrzeni wektorowej: \n",
    "conv_n_dim = 64\n",
    "conv_n_unique_words = 5000 \n",
    "conv_max_review_length = 400\n",
    "conv_pad_type = trunc_type = 'pre'\n",
    "\n",
    "#parametr dropoutu\n",
    "conv_drop_embed = 0.2\n",
    "\n",
    "# parametry architektury konwolucyjnej:\n",
    "n_conv = 256 # filtry/kernele\n",
    "k_conv = 3 # długość kernela\n",
    "\n",
    "# parametry warstwy gęstej: \n",
    "n_dense = 256\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ustawmy hiperparametry dla klasyfikatora rekurencyjnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lokalizacja wyjściowa dla wag:\n",
    "rnn_output_dir = 'model_output/rnn'\n",
    "\n",
    "# parametry treningu:\n",
    "rnn_epochs = 16\n",
    "rnn_batch_size = 128\n",
    "\n",
    "# osadzenie przestrzeni wektorowej: \n",
    "rnn_n_dim = 64 \n",
    "rnn_n_unique_words = 10000 \n",
    "rnn_max_review_length = 100 #zmniejszone z powodu szybciej zanikającego gradientu w jednostkach rekurencyjnych\n",
    "rnn_pad_type = trunc_type = 'pre'\n",
    "rnn_drop_embed = 0.2 \n",
    "\n",
    "# parametry architektury rekurencyjnej:\n",
    "n_rnn = 256 \n",
    "drop_rnn = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Załaduj dane treningowe i walidacyjne z parametrem liczby uwzględnianych słów (odrębnie dla obu klasyfikatorów)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_rnn, y_train_rnn), (x_val_rnn, y_val_rnn) = imdb.load_data(num_words=conv_n_unique_words)\n",
    "(x_train_conv, y_train_conv), (x_val_conv, y_val_conv) = imdb.load_data(num_words=rnn_n_unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przetwórz wszystkie załadowane dane poprzez ujednolicenie wielkości danych wejściowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dla rnn\n",
    "x_train_rnn = pad_sequences(x_train_rnn, maxlen=rnn_max_review_length, padding=rnn_pad_type, truncating=trunc_type)\n",
    "x_val_rnn = pad_sequences(x_val_rnn, maxlen=rnn_max_review_length, padding=rnn_pad_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dla conv\n",
    "x_train_conv = pad_sequences(x_train_conv, maxlen=conv_max_review_length, padding=conv_pad_type, truncating=trunc_type)\n",
    "x_val_conv = pad_sequences(x_val_conv, maxlen=conv_max_review_length, padding=conv_pad_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Zaprojektuj obie architektury sieci, wybierając odpowiednie zaimportowane obiekty i zadeklarowane wyżej hiperparametry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ConvNN\n",
    "- odpowiednio osadź przestrzeń wektorową (embedding), \n",
    "- dodaj przestrzenny dropout z odpowiednim parametrem i wybraną funkcją aktywacji\n",
    "- utwórz warstwę konwolucyjną jednowymiarową z odpowiednimi hiperparametrami\n",
    "- dodaj warstwę redukującą - globalny jednowymiarowy max-pooling\n",
    "- uzupełnij sieć o warstwę gęstą z wybraną funkcją aktywacji i dropoutem\n",
    "- zakończ warstwą klasyfikującą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = Sequential([\n",
    "    Embedding(input_dim=conv_n_unique_words, output_dim=conv_n_dim, input_length=conv_max_review_length),\n",
    "    SpatialDropout1D(conv_drop_embed),\n",
    "    Conv1D(filters=n_conv, kernel_size=k_conv, padding='same', activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(n_dense, activation='relu'),\n",
    "    Dropout(dropout),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN\n",
    "- odpowiednio osadź przestrzeń wektorową (embedding), \n",
    "- dodaj przestrzenny dropout z odpowiednim parametrem i wybraną funkcją aktywacji\n",
    "- utwórz prostą warstwę rekurencyjną z odpowiednimi hiperparametrami\n",
    "- zakończ warstwą klasyfikującą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = Sequential([\n",
    "    Embedding(input_dim=rnn_n_unique_words, output_dim=rnn_n_dim, input_length=rnn_max_review_length),\n",
    "    SpatialDropout1D(rnn_drop_embed),\n",
    "    SimpleRNN(n_rnn, return_sequences=True, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skompiluj oba modele z odpowiednimi parametrami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model:\n",
    "model_conv.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stwórz obiekty do rejestrowania wag dla każdego z modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dla rnn\n",
    "checkpoint_rnn = ModelCheckpoint(os.path.join(rnn_output_dir, 'rnn_weights.h5'), monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "if not os.path.exists(rnn_output_dir):\n",
    "    os.makedirs(rnn_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dla conv\n",
    "checkpoint_conv = ModelCheckpoint(os.path.join(conv_output_dir, 'conv_weights.h5'), monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "if not os.path.exists(conv_output_dir):\n",
    "    os.makedirs(conv_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naucz oba modele z użyciem zbiorów walidacyjnych, z odpowiednimi zadeklarowanymi wyżej parametrami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn\n",
    "history_rnn = model_rnn.fit(x_train_rnn, y_train_rnn, epochs=rnn_epochs, batch_size=rnn_batch_size, validation_data=(x_val_rnn, y_val_rnn), callbacks=[checkpoint_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv\n",
    "history_conv = model_conv.fit(x_train_conv, y_train_conv, epochs=conv_epochs, batch_size=conv_batch_size, validation_data=(x_val_conv, y_val_conv), callbacks=[checkpoint_conv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Wykonaj inferencję (ewaluację) obu modeli uprzednio ładując wagi z ich najlepszych epok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.load_weights(os.path.join(conv_output_dir, 'conv_weights.04-0.00.h5'))\n",
    "model_rnn.load_weights(os.path.join(rnn_output_dir, 'rnn_weights.04-0.00.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred_conv = model_conv.predict(x_val_conv)\n",
    "y_pred_rnn = model_rnn.predict(x_val_rnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zestaw na jednym wykresie histogramy dla danych walidacyjnych obu modeli oraz, na kolejnym wykresie, krzywe ROC obu klasyfikatorów,  a następnie - patrząc na oba te wykresy oraz statystyki uczenia, zapisz trzy sensowne wnioski co do wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(y_pred_conv, bins=20, label='conv')\n",
    "ax.hist(y_pred_rnn, bins=20, label='rnn')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(roc_curve(y_val_conv, y_pred_conv), label='conv')\n",
    "ax.plot(roc_curve(y_val_rnn, y_pred_rnn), label='rnn')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tu wnioski**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
