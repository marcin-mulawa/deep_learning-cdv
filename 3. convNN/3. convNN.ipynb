{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci splotowe (Convolutional Neural Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie danych\n",
    "Wykorzystamy w zadaniu zbiór Fashion-MNIST. Jak zwykle zaczynamy od pobrania danych, sprawdzamy krótko jak wyglądają, a następnie definiujemy miarę trafności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "target_directory = \"fmnist\"\n",
    "\n",
    "fmnist_real_train = FashionMNIST(target_directory, train=True, download=True, transform=transforms.ToTensor())\n",
    "fmnist_test = FashionMNIST(target_directory, train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_train, fmnist_validation = data.random_split(fmnist_real_train, (48000, 12000))\n",
    "len(fmnist_train), len(fmnist_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = data.DataLoader(fmnist_train, batch_size=64, shuffle=True)\n",
    "dataiter = iter(trainloader)\n",
    "images,_ = dataiter.next()\n",
    "plt.figure(figsize=(5,5))\n",
    "for k in range(12):\n",
    "    plt.subplot(3, 4, k+1)\n",
    "    plt.imshow(images[k].numpy().squeeze(), cmap='gray_r')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(logits, expected):\n",
    "    pred = logits.argmax(dim=1)\n",
    "    return (pred == expected).type(torch.float).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warstwa splotowa (konwolucyjna)\n",
    "\n",
    "Warstwa splotowa przemieszcza jądro (ang. *kernel*) po obrazie kawałek po kawałku, oblicza wynik i zapamiętuje go w macierzy wyjściowej. Przetwarzany obrazek jest często uzupełniany o zera (ang. *padding*), ponieważ bez tego macierz wynikowa byłaby mniejsza niż obrazek wejściowy. Piksel w macierzy wyjściowej obliczany jest następująco: każdy z pikseli obrazu wejściowego jest mnożony przez odpowiadającą mu wartość w filtrze, a tak uzyskane 9 wartości jest sumowane. Następnie ten sam filtr wykorzystywany jest do obliczenia kolejnego piksela. Filtr składa się z wag splotowej sieci neuronowej, co oznacza, że to on podlega uczeniu.\n",
    "\n",
    "Jądro nie musi przesuwać się za każdym razem o 1 piksel, może mieć większy krok (ang. *stride*).\n",
    "\n",
    "Jeśli obrazek jest kolorowy możemy go postrzegać jako kilka obrazków monochromatycznych.\n",
    "\n",
    "Przykład: [jak działa sieć konwolucyjna](https://bfirst.tech/wp-content/uploads/2019/06/sieci_konwolucyjne_gif-1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warstwę splotową w PyTorch realizuje klasa [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d). Pierwsze jej trzy parametry są obowiązkowe, są to:\n",
    "\n",
    "- liczba map na wejściu, \n",
    "- liczba map na wyjściu, \n",
    "- rozmiar jądra (jedna liczba jeżeli ma być kwadratowe albo para liczb jeżeli ma być prostokątem).\n",
    "\n",
    "Będziemy budowali krok po kroku listę, w której będziemy umieszczali kolejne warstwy sieci.\n",
    "\n",
    "Rozpoczniemy od dodania warstwy splotowej.\n",
    "\n",
    "Obrazki MNIST są monochromatyczne, więc mamy tylko 1 kanał wejściowy.\n",
    "\n",
    "Przyjmimy, że na wyjściu będziemy mieli **5 map**, każdą na bazie kwadratowego filtra o boku 3.\n",
    "Żeby nie zmniejszyć zbyt szybko obrazka dodamy po 1 pikselu paddingu z każdej strony - jak w ww. przykładzie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Conv2d(1, 5, 3, padding=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warstwa splotowa - podobnie jak warstwa liniowa (`nn.Linear`) - jest tylko sumą. By wprowadzić nieliniowość, zastosujemy *Leaky ReLU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.append(nn.LeakyReLU())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Druga warstwa jest nazywana łączącą (ang. *pooling layer*). Jej zadaniem jest zmniejszenie wymiarów cech konwolucyjnych, wyznaczonych w poprzedniej warstwie, przy zachowaniu kluczowych szczegółów. Odpowiada również za redukcję szumu. \n",
    "\n",
    "Warstwa ta, podobnie jak warstwa splotowa przesuwa filtr przez obraz, ale ten filtr jest pozbawiony parametrów: służy albo do wybierania maksimum (ang. *max pooling*) albo do obliczania średniej arytmetycznej (ang. *average pooling*). Każda mapa analizowana jest oddzielnie, więc zawsze pozostajemy w dwóch wymiarach.\n",
    "\n",
    "Kontynuacja przykładu: [jak działa pooling](https://bfirst.tech/wp-content/uploads/2019/06/sieci_konwolucyjne_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodamy zatem do naszej sieci neuronowej *max pooling*, realizowany za pomocą klasy `nn.MaxPool2d`, z jądrem rozmiaru $3 x 3$ i uzupełnieniem o 1 piksel z każdej strony."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.append(nn.MaxPool2d(3, padding=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 1a. Mamy 5 map, a jakiego rozmiaru będą one na tym etapie przetwarzania, jeżeli wejście miało mapę rozmiaru $28 x 28$, a jądro ma rozmiar 3?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tu odpowiedź"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spłaszczenie i klasyfikacja\n",
    "\n",
    "Na tym etapie każdy obiekt przetwarzany przez sieć jest trójwymiarowy, czyli składa się z pewnej liczby dwuwymiarowych map. Do klasyfikacji wykorzystamy sumującą warstwę liniową `nn.Linear`. Nie jest to dla niej odpowiedni format wejścia. Zatem najpierw za pomocą klasy `nn.Flatten` ułożymy piksele jeden za drugim w wektor.\n",
    "\n",
    "**Zadanie 1b. Klasyfikujemy do 10 klas, więc mamy 10 neuronów wyjściowych, a ilu potrzeba wejść? Uzupełnij kod (w miejscu ...) na podstawie wyników zad. 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.append(torch.nn.Flatten())\n",
    "layers.append(nn.Linear(..., 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konfiguracja sieci\n",
    "\n",
    "**Zadanie 2. Połącz gotowe warstwy w jeden sekwencyjny moduł, jako funkcję straty zadeklaruj entropię krzyżową/skrośną, a do optymalizacji parametrów modelu użyj optymalizatora Adam.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ...\n",
    "\n",
    "cost = ...\n",
    "opt = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie z wykorzystaniem wczesnego zatrzymania\n",
    "\n",
    "Wczesne zatrzymanie (ang. *early stopping*) składa się z następujących kroków:\n",
    "- co określoną liczbę epok uczenia obliczamy miarę oceny (np. trafność klasyfikacji) na zbiorze walidującym\n",
    "- jeżeli nastąpiła poprawa w stosunku do poprzedniego razu, zapamiętujemy obecne wartości wag sieci neuronowej\n",
    "- jeżeli przez określoną liczbę epok nie następuje poprawa, przerywamy uczenie i przywracamy wagi ostatniego najlepszego modelu\n",
    "\n",
    "**Zadanie 3. Poniższy kawałek kodu oblicza trafność na zbiorze walidującym co epokę. Dodaj kod przerywający uczenie, jeżeli przez 5 kolejnych epok nie nastąpiła poprawa. Wyświetlaj wynik i numer porządkowy aktualnie najlepszej epoki, skorzystaj z zadeklarowanych zmiennych, podaj informację o fakcie wczesnego zatrzymania. Pamiętaj że najlepszy model powinien zostać zapisany, sprawdź w dokumentacji biblioteki pytorch jak to zrobić. Na końcu załaduj najlepszy model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "validation_acc = []\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_epoch = None\n",
    "max_epoch = 10000\n",
    "no_improvement = 5\n",
    "batch_size = 512\n",
    "\n",
    "for n_epoch in range(max_epoch):\n",
    "    model.train()\n",
    "    loader = data.DataLoader(fmnist_train, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    epoch_loss = []\n",
    "    for X_batch, y_batch in loader:\n",
    "        opt.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = cost(logits, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()        \n",
    "        epoch_loss.append(loss.detach())\n",
    "    train_loss.append(torch.tensor(epoch_loss).mean())\n",
    "    model.eval()\n",
    "    loader = data.DataLoader(fmnist_validation, batch_size=len(fmnist_validation), shuffle=False)\n",
    "    X, y = next(iter(loader))\n",
    "    logits = model(X)\n",
    "    acc = compute_acc(logits, y).detach()\n",
    "    validation_acc.append(acc)\n",
    "    \n",
    "    #tutaj napisz kod wczesnego zatrzymania\n",
    "    \n",
    "    \n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przyjrzyj się poniższym wykresom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Trafność na zbiorze walidacyjnym. Kropka oznacza najlepszą trafność.')\n",
    "plt.plot(validation_acc, label='Trafność na zbiorze walidacyjnym')\n",
    "plt.plot(best_epoch, best_acc, 'bo', label='Najlepsza trafność')\n",
    "plt.show()\n",
    "plt.title('Błąd na zbiorze treningowym')\n",
    "plt.plot(train_loss)\n",
    "plt.show()\n",
    "k = max(3*no_improvement, 0)\n",
    "plt.title('Ostatnie {} epok'.format(k))\n",
    "plt.plot(validation_acc[-k:])\n",
    "plt.plot(best_epoch-(len(validation_acc)-k), best_acc, 'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 4. Dlaczego wczesne zatrzymanie jest realizowane na zbiorze walidującym, a nie na zbiorze uczącym albo na zbiorze testowym?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tu miejsce na odpowiedź"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 5. Przyjrzyj się jeszcze raz kodowi odpowiedzialnemu za epokę uczenia. Wykorzystaj linijki odpowiedzialne tam za obliczanie trafności i oblicz trafność klasyfikacji: na zbiorze walidującym oraz na zbiorze testowym. Czy uzyskane wartości się różnią? Co może być powodem różnic?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "#tutaj trafność na zbiorze walidacyjnym\n",
    "print(\"Dokladnosc na zbiorze walidacyjnym\", acc_val)\n",
    "\n",
    "#tutaj trafność na zbiorze testowym\n",
    "print(\"Dokladnosc na zbiorze testowym\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tu napisz komentarz do odpowiedzi**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
