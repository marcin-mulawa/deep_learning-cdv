{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcin-mulawa/deep_learning-cdv/blob/main/6.%20dense_sentiment_classifier/6.%20dense_sentiment_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahUZuAfz8Jje"
      },
      "source": [
        "# Dense Sentiment Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re0ecmVI8Jjk"
      },
      "source": [
        "#### Zaprojektujmy gęstą sieć do klasyfikacji sentymentu (nastroju / nastawienia) recenzji filmów z portalu IMDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixsGb9tY8Jjm"
      },
      "source": [
        "#### Załadujmy zależności (zwróć uwagę na nowy rodzaj warstwy - Embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5At1PKQp8Jjp"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "import os\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc, RocCurveDisplay\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg5wX2Dd8Jjz"
      },
      "source": [
        "**Ustawmy stałe i hiperparametry (gdy wiemy, że przetwarzanie zbioru danych będzie bardziej złożone, warto to robić już na początku), wybierz dowolną liczbę epok i batch_size. Przypatrz się co oznaczają wszystkie hiperparametry, przyda się to w zrozumieniu całego procesu przetwarzania**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lYLOM99-8Jj2"
      },
      "outputs": [],
      "source": [
        "output_dir = 'output' #sieć będzie generować wyjście, więc określamy jego lokalizację\n",
        "\n",
        "#hiperparametry treningu\n",
        "epochs = 20\n",
        "batch_size = 512\n",
        "\n",
        "# hiperparametry przetwarzania tekstu: \n",
        "n_dim = 64 #liczba wymiarów przestrzeni wektorów słów\n",
        "n_unique_words = 5000 # liczba uwzględnianych najpopularniejszych słów w korpusie recenzji filmów\n",
        "n_words_to_skip = 50 # liczba najczęstszych stop words do usunięcia\n",
        "max_review_length = 100 # długość recenzji, dłuższe będą przycinane, a krótsze sztucznie wydłużane (tak jakby padding) \n",
        "pad_type = trunc_type = 'pre' #przycinanie i wydłużanie będzie miało miejsce na początku recenzji (alternatywa do 'post')\n",
        "\n",
        "# hiperparametry sieci: \n",
        "n_dense = 64\n",
        "dropout = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaLx4yZ48Jj9"
      },
      "source": [
        "#### Załadujmy dane"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD9X0yJg8Jj_"
      },
      "source": [
        "Zbiór składa się z 50 000 recenzji - połowa w zbiorze treningowym, połowa w walidacyjnym. Wraz z recenzją dodawane są liczby gwiazdek jako oceną od 1 do 10. Recenzję ocenioną na <=4 gwiazdki uznaje się za negatywną (y=0), a na >=7 gwiazdek za pozytywną (y=1), neutralnych recenzji nie ma w zbiorze.\n",
        "\n",
        "W metodzie `load_data` kryje się już kilka metod automatycznego przetwarzania tekstu:\n",
        " - tokenizacja\n",
        " - usuwanie znaków interpunkcyjnych\n",
        " - zamiana na małe litery\n",
        " - zamiana słów na całkowitoliczbowe indeksy\n",
        " - ograniczenie wielkości słownika (num_words)\n",
        " - usunięcie najpopularniejszych stop words (skip_top)\n",
        " - brakuje w niej ewentualnego stemmingu i lematyzacji oraz analizy n-gramów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6r44JKj-8JkA"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words, skip_top=n_words_to_skip) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57c0BT7yd5mL"
      },
      "source": [
        "#### Wyświetlmy pierwsze recenzje ze zbioru treningowego\n",
        "\n",
        "Tokeny są reprezentowane przez całkowitoliczbowe indeksy, posortowane wg częstości występowania. Pierwsze kilka liczb ma specjalne znaczenie:\n",
        " - 0 - token dopełniający\n",
        " - 1 - token startowy (początek recenzji), ale tutaj jest to token nieznany gdyż token startowy znajduje się wśród 50 najpopularniejszych tokenów\n",
        " - 2 - token występujący bardzo często (czyli usunięty jako stop word) lub bardzo rzadko (czyli nieuwzględniony), zastąpiony w związku z tym tokenem 'nieznany' (UNK)\n",
        " - 3 - słowo które występuje w korpusie najczęściej\n",
        " - 4 - drugie najczęściej występujące słowo\n",
        " - 5 - trzecie najczęściej występujące słowo itd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqiUnLzY8JkK",
        "outputId": "37270dd6-0ece-44df-aaa4-3995809b66a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([2, 2, 2, 2, 2, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 2, 173, 2, 256, 2, 2, 100, 2, 838, 112, 50, 670, 2, 2, 2, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 2, 2, 172, 4536, 1111, 2, 546, 2, 2, 447, 2, 192, 50, 2, 2, 147, 2025, 2, 2, 2, 2, 1920, 4613, 469, 2, 2, 71, 87, 2, 2, 2, 530, 2, 76, 2, 2, 1247, 2, 2, 2, 515, 2, 2, 2, 626, 2, 2, 2, 62, 386, 2, 2, 316, 2, 106, 2, 2, 2223, 2, 2, 480, 66, 3785, 2, 2, 130, 2, 2, 2, 619, 2, 2, 124, 51, 2, 135, 2, 2, 1415, 2, 2, 2, 2, 215, 2, 77, 52, 2, 2, 407, 2, 82, 2, 2, 2, 107, 117, 2, 2, 256, 2, 2, 2, 3766, 2, 723, 2, 71, 2, 530, 476, 2, 400, 317, 2, 2, 2, 2, 1029, 2, 104, 88, 2, 381, 2, 297, 98, 2, 2071, 56, 2, 141, 2, 194, 2, 2, 2, 226, 2, 2, 134, 476, 2, 480, 2, 144, 2, 2, 2, 51, 2, 2, 224, 92, 2, 104, 2, 226, 65, 2, 2, 1334, 88, 2, 2, 283, 2, 2, 4472, 113, 103, 2, 2, 2, 2, 2, 178, 2]),\n",
              "       list([2, 194, 1153, 194, 2, 78, 228, 2, 2, 1463, 4369, 2, 134, 2, 2, 715, 2, 118, 1634, 2, 394, 2, 2, 119, 954, 189, 102, 2, 207, 110, 3103, 2, 2, 69, 188, 2, 2, 2, 2, 2, 249, 126, 93, 2, 114, 2, 2300, 1523, 2, 647, 2, 116, 2, 2, 2, 2, 229, 2, 340, 1322, 2, 118, 2, 2, 130, 4901, 2, 2, 1002, 2, 89, 2, 952, 2, 2, 2, 455, 2, 2, 2, 2, 1543, 1905, 398, 2, 1649, 2, 2, 2, 163, 2, 3215, 2, 2, 1153, 2, 194, 775, 2, 2, 2, 349, 2637, 148, 605, 2, 2, 2, 123, 125, 68, 2, 2, 2, 349, 165, 4362, 98, 2, 2, 228, 2, 2, 2, 1157, 2, 299, 120, 2, 120, 174, 2, 220, 175, 136, 50, 2, 4373, 228, 2, 2, 2, 656, 245, 2350, 2, 2, 2, 131, 152, 491, 2, 2, 2, 2, 1212, 2, 2, 2, 371, 78, 2, 625, 64, 1382, 2, 2, 168, 145, 2, 2, 1690, 2, 2, 2, 1355, 2, 2, 2, 52, 154, 462, 2, 89, 78, 285, 2, 145, 95]),\n",
              "       list([2, 2, 2, 2, 2, 2, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 2, 71, 149, 2, 2, 112, 2, 2401, 311, 2, 2, 3711, 2, 75, 2, 1829, 296, 2, 86, 320, 2, 534, 2, 263, 4821, 1301, 2, 1873, 2, 89, 78, 2, 66, 2, 2, 360, 2, 2, 58, 316, 334, 2, 2, 1716, 2, 645, 662, 2, 257, 85, 1200, 2, 1228, 2578, 83, 68, 3912, 2, 2, 165, 1539, 278, 2, 69, 2, 780, 2, 106, 2, 2, 1338, 2, 2, 2, 2, 215, 2, 610, 2, 2, 87, 326, 2, 2300, 2, 2, 2, 2, 272, 2, 57, 2, 2, 2, 2, 2, 2, 2307, 51, 2, 170, 2, 595, 116, 595, 1352, 2, 191, 79, 638, 89, 2, 2, 2, 2, 106, 607, 624, 2, 534, 2, 227, 2, 129, 113]),\n",
              "       list([2, 2, 2, 2, 2, 2804, 2, 2040, 432, 111, 153, 103, 2, 1494, 2, 70, 131, 67, 2, 61, 2, 744, 2, 3715, 761, 61, 2, 452, 2, 2, 985, 2, 2, 59, 166, 2, 105, 216, 1239, 2, 1797, 2, 2, 2, 2, 744, 2413, 2, 2, 2, 687, 2, 2, 2, 2, 2, 3693, 2, 2, 2, 121, 59, 456, 2, 2, 2, 265, 2, 575, 111, 153, 159, 59, 2, 1447, 2, 2, 586, 482, 2, 2, 96, 59, 716, 2, 2, 172, 65, 2, 579, 2, 2, 2, 1615, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 464, 2, 314, 2, 2, 2, 719, 605, 2, 2, 202, 2, 310, 2, 3772, 3501, 2, 2722, 58, 2, 2, 537, 2116, 180, 2, 2, 413, 173, 2, 263, 112, 2, 152, 377, 2, 537, 263, 846, 579, 178, 54, 75, 71, 476, 2, 413, 263, 2504, 182, 2, 2, 75, 2306, 922, 2, 279, 131, 2895, 2, 2867, 2, 2, 2, 921, 2, 192, 2, 1219, 3890, 2, 2, 217, 4122, 1710, 537, 2, 1236, 2, 736, 2, 2, 61, 403, 2, 2, 2, 61, 4494, 2, 2, 4494, 159, 90, 263, 2311, 4319, 309, 2, 178, 2, 82, 4319, 2, 65, 2, 2, 145, 143, 2, 2, 2, 537, 746, 537, 537, 2, 2, 2, 2, 594, 2, 2, 94, 2, 3987, 2, 2, 2, 2, 538, 2, 1795, 246, 2, 2, 2, 2, 635, 2, 2, 51, 408, 2, 94, 318, 1382, 2, 2, 2, 2683, 936, 2, 2, 2, 2, 2, 2, 2, 1885, 2, 1118, 2, 80, 126, 842, 2, 2, 2, 2, 4726, 2, 4494, 2, 1550, 3633, 159, 2, 341, 2, 2733, 2, 4185, 173, 2, 90, 2, 2, 2, 2, 2, 1784, 86, 1117, 2, 3261, 2, 2, 2, 2, 2, 2, 2841, 2, 2, 1010, 2, 793, 2, 2, 1386, 1830, 2, 2, 246, 50, 2, 2, 2750, 1944, 746, 90, 2, 2, 2, 124, 2, 882, 2, 882, 496, 2, 2, 2213, 537, 121, 127, 1219, 130, 2, 2, 494, 2, 124, 2, 882, 496, 2, 341, 2, 2, 846, 2, 2, 2, 2, 1906, 2, 97, 2, 236, 2, 1311, 2, 2, 2, 2, 2, 2, 2, 91, 2, 3987, 70, 2, 882, 2, 579, 2, 2, 2, 2, 2, 537, 2, 2, 2, 2, 65, 2, 537, 75, 2, 1775, 3353, 2, 1846, 2, 2, 2, 154, 2, 2, 518, 53, 2, 2, 2, 3211, 882, 2, 399, 2, 75, 257, 3807, 2, 2, 2, 2, 456, 2, 65, 2, 2, 205, 113, 2, 2, 2, 2, 2, 2, 2, 242, 2, 91, 1202, 2, 2, 2070, 307, 2, 2, 2, 126, 93, 2, 2, 2, 188, 1076, 3222, 2, 2, 2, 2, 2348, 537, 2, 53, 537, 2, 82, 2, 2, 2, 2, 2, 280, 2, 219, 2, 2, 431, 758, 859, 2, 953, 1052, 2, 2, 2, 2, 94, 2, 2, 238, 60, 2, 2, 2, 804, 2, 2, 2, 2, 132, 2, 67, 2, 2, 2, 2, 283, 2, 2, 2, 2, 2, 242, 955, 2, 2, 279, 2, 2, 2, 1685, 195, 2, 238, 60, 796, 2, 2, 671, 2, 2804, 2, 2, 559, 154, 888, 2, 726, 50, 2, 2, 2, 2, 566, 2, 579, 2, 64, 2574]),\n",
              "       list([2, 249, 1323, 2, 61, 113, 2, 2, 2, 1637, 2, 2, 56, 2, 2401, 2, 457, 88, 2, 2626, 1400, 2, 3171, 2, 70, 79, 2, 706, 919, 2, 2, 355, 340, 355, 1696, 96, 143, 2, 2, 2, 289, 2, 61, 369, 71, 2359, 2, 2, 2, 131, 2073, 249, 114, 249, 229, 249, 2, 2, 2, 126, 110, 2, 473, 2, 569, 61, 419, 56, 429, 2, 1513, 2, 2, 534, 95, 474, 570, 2, 2, 124, 138, 88, 2, 421, 1543, 52, 725, 2, 61, 419, 2, 2, 1571, 2, 1543, 2, 2, 2, 2, 2, 296, 2, 3524, 2, 2, 421, 128, 74, 233, 334, 207, 126, 224, 2, 562, 298, 2167, 1272, 2, 2601, 2, 516, 988, 2, 2, 79, 120, 2, 595, 2, 784, 2, 3171, 2, 165, 170, 143, 2, 2, 2, 2, 2, 226, 251, 2, 61, 113]),\n",
              "       list([2, 778, 128, 74, 2, 630, 163, 2, 2, 1766, 2, 1051, 2, 2, 85, 156, 2, 2, 148, 139, 121, 664, 665, 2, 2, 1361, 173, 2, 749, 2, 2, 3804, 2, 2, 226, 65, 2, 2, 127, 2, 2, 2, 2])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "x_train[0:6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZLwLjQBd5mL"
      },
      "source": [
        "#### Wyświetlmy długość pierwszych recenzji (liczbę tokenów w nich) oraz ich sentyment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKE2mCFb8JkS",
        "outputId": "e9eb1c45-4353-4108-b5d1-402220293847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218\n",
            "189\n",
            "141\n",
            "550\n",
            "147\n",
            "43\n"
          ]
        }
      ],
      "source": [
        "for x in x_train[0:6]:\n",
        "    print(len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7oz-Qrk8JkW",
        "outputId": "bb8c7fcb-e360-4bec-baab-2da0bb925454"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "y_train[0:6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UZJsspA8Jkj"
      },
      "source": [
        "#### Sprawdźmy jak de facto wyglądają słowa, kryjące się pod indeksami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IAauXkjO8Jkk"
      },
      "outputs": [],
      "source": [
        "word_index = tensorflow.keras.datasets.imdb.get_word_index()\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"PAD\"] = 0\n",
        "word_index[\"START\"] = 1\n",
        "word_index[\"UNK\"] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eTd9QcLW8Jkp",
        "outputId": "a028aea1-d7dd-4149-80c6-c5fdc3a2bc5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fawn': 34704,\n",
              " 'tsukino': 52009,\n",
              " 'nunnery': 52010,\n",
              " 'sonja': 16819,\n",
              " 'vani': 63954,\n",
              " 'woods': 1411,\n",
              " 'spiders': 16118,\n",
              " 'hanging': 2348,\n",
              " 'woody': 2292,\n",
              " 'trawling': 52011,\n",
              " \"hold's\": 52012,\n",
              " 'comically': 11310,\n",
              " 'localized': 40833,\n",
              " 'disobeying': 30571,\n",
              " \"'royale\": 52013,\n",
              " \"harpo's\": 40834,\n",
              " 'canet': 52014,\n",
              " 'aileen': 19316,\n",
              " 'acurately': 52015,\n",
              " \"diplomat's\": 52016,\n",
              " 'rickman': 25245,\n",
              " 'arranged': 6749,\n",
              " 'rumbustious': 52017,\n",
              " 'familiarness': 52018,\n",
              " \"spider'\": 52019,\n",
              " 'hahahah': 68807,\n",
              " \"wood'\": 52020,\n",
              " 'transvestism': 40836,\n",
              " \"hangin'\": 34705,\n",
              " 'bringing': 2341,\n",
              " 'seamier': 40837,\n",
              " 'wooded': 34706,\n",
              " 'bravora': 52021,\n",
              " 'grueling': 16820,\n",
              " 'wooden': 1639,\n",
              " 'wednesday': 16821,\n",
              " \"'prix\": 52022,\n",
              " 'altagracia': 34707,\n",
              " 'circuitry': 52023,\n",
              " 'crotch': 11588,\n",
              " 'busybody': 57769,\n",
              " \"tart'n'tangy\": 52024,\n",
              " 'burgade': 14132,\n",
              " 'thrace': 52026,\n",
              " \"tom's\": 11041,\n",
              " 'snuggles': 52028,\n",
              " 'francesco': 29117,\n",
              " 'complainers': 52030,\n",
              " 'templarios': 52128,\n",
              " '272': 40838,\n",
              " '273': 52031,\n",
              " 'zaniacs': 52133,\n",
              " '275': 34709,\n",
              " 'consenting': 27634,\n",
              " 'snuggled': 40839,\n",
              " 'inanimate': 15495,\n",
              " 'uality': 52033,\n",
              " 'bronte': 11929,\n",
              " 'errors': 4013,\n",
              " 'dialogs': 3233,\n",
              " \"yomada's\": 52034,\n",
              " \"madman's\": 34710,\n",
              " 'dialoge': 30588,\n",
              " 'usenet': 52036,\n",
              " 'videodrome': 40840,\n",
              " \"kid'\": 26341,\n",
              " 'pawed': 52037,\n",
              " \"'girlfriend'\": 30572,\n",
              " \"'pleasure\": 52038,\n",
              " \"'reloaded'\": 52039,\n",
              " \"kazakos'\": 40842,\n",
              " 'rocque': 52040,\n",
              " 'mailings': 52041,\n",
              " 'brainwashed': 11930,\n",
              " 'mcanally': 16822,\n",
              " \"tom''\": 52042,\n",
              " 'kurupt': 25246,\n",
              " 'affiliated': 21908,\n",
              " 'babaganoosh': 52043,\n",
              " \"noe's\": 40843,\n",
              " 'quart': 40844,\n",
              " 'kids': 362,\n",
              " 'uplifting': 5037,\n",
              " 'controversy': 7096,\n",
              " 'kida': 21909,\n",
              " 'kidd': 23382,\n",
              " \"error'\": 52044,\n",
              " 'neurologist': 52045,\n",
              " 'spotty': 18513,\n",
              " 'cobblers': 30573,\n",
              " 'projection': 9881,\n",
              " 'fastforwarding': 40845,\n",
              " 'sters': 52046,\n",
              " \"eggar's\": 52047,\n",
              " 'etherything': 52048,\n",
              " 'gateshead': 40846,\n",
              " 'airball': 34711,\n",
              " 'unsinkable': 25247,\n",
              " 'stern': 7183,\n",
              " \"cervi's\": 52049,\n",
              " 'dnd': 40847,\n",
              " 'dna': 11589,\n",
              " 'insecurity': 20601,\n",
              " \"'reboot'\": 52050,\n",
              " 'trelkovsky': 11040,\n",
              " 'jaekel': 52051,\n",
              " 'sidebars': 52052,\n",
              " \"sforza's\": 52053,\n",
              " 'distortions': 17636,\n",
              " 'mutinies': 52054,\n",
              " 'sermons': 30605,\n",
              " '7ft': 40849,\n",
              " 'boobage': 52055,\n",
              " \"o'bannon's\": 52056,\n",
              " 'populations': 23383,\n",
              " 'chulak': 52057,\n",
              " 'mesmerize': 27636,\n",
              " 'quinnell': 52058,\n",
              " 'yahoo': 10310,\n",
              " 'meteorologist': 52060,\n",
              " 'beswick': 42580,\n",
              " 'boorman': 15496,\n",
              " 'voicework': 40850,\n",
              " \"ster'\": 52061,\n",
              " 'blustering': 22925,\n",
              " 'hj': 52062,\n",
              " 'intake': 27637,\n",
              " 'morally': 5624,\n",
              " 'jumbling': 40852,\n",
              " 'bowersock': 52063,\n",
              " \"'porky's'\": 52064,\n",
              " 'gershon': 16824,\n",
              " 'ludicrosity': 40853,\n",
              " 'coprophilia': 52065,\n",
              " 'expressively': 40854,\n",
              " \"india's\": 19503,\n",
              " \"post's\": 34713,\n",
              " 'wana': 52066,\n",
              " 'wang': 5286,\n",
              " 'wand': 30574,\n",
              " 'wane': 25248,\n",
              " 'edgeways': 52324,\n",
              " 'titanium': 34714,\n",
              " 'pinta': 40855,\n",
              " 'want': 181,\n",
              " 'pinto': 30575,\n",
              " 'whoopdedoodles': 52068,\n",
              " 'tchaikovsky': 21911,\n",
              " 'travel': 2106,\n",
              " \"'victory'\": 52069,\n",
              " 'copious': 11931,\n",
              " 'gouge': 22436,\n",
              " \"chapters'\": 52070,\n",
              " 'barbra': 6705,\n",
              " 'uselessness': 30576,\n",
              " \"wan'\": 52071,\n",
              " 'assimilated': 27638,\n",
              " 'petiot': 16119,\n",
              " 'most\\x85and': 52072,\n",
              " 'dinosaurs': 3933,\n",
              " 'wrong': 355,\n",
              " 'seda': 52073,\n",
              " 'stollen': 52074,\n",
              " 'sentencing': 34715,\n",
              " 'ouroboros': 40856,\n",
              " 'assimilates': 40857,\n",
              " 'colorfully': 40858,\n",
              " 'glenne': 27639,\n",
              " 'dongen': 52075,\n",
              " 'subplots': 4763,\n",
              " 'kiloton': 52076,\n",
              " 'chandon': 23384,\n",
              " \"effect'\": 34716,\n",
              " 'snugly': 27640,\n",
              " 'kuei': 40859,\n",
              " 'welcomed': 9095,\n",
              " 'dishonor': 30074,\n",
              " 'concurrence': 52078,\n",
              " 'stoicism': 23385,\n",
              " \"guys'\": 14899,\n",
              " \"beroemd'\": 52080,\n",
              " 'butcher': 6706,\n",
              " \"melfi's\": 40860,\n",
              " 'aargh': 30626,\n",
              " 'playhouse': 20602,\n",
              " 'wickedly': 11311,\n",
              " 'fit': 1183,\n",
              " 'labratory': 52081,\n",
              " 'lifeline': 40862,\n",
              " 'screaming': 1930,\n",
              " 'fix': 4290,\n",
              " 'cineliterate': 52082,\n",
              " 'fic': 52083,\n",
              " 'fia': 52084,\n",
              " 'fig': 34717,\n",
              " 'fmvs': 52085,\n",
              " 'fie': 52086,\n",
              " 'reentered': 52087,\n",
              " 'fin': 30577,\n",
              " 'doctresses': 52088,\n",
              " 'fil': 52089,\n",
              " 'zucker': 12609,\n",
              " 'ached': 31934,\n",
              " 'counsil': 52091,\n",
              " 'paterfamilias': 52092,\n",
              " 'songwriter': 13888,\n",
              " 'shivam': 34718,\n",
              " 'hurting': 9657,\n",
              " 'effects': 302,\n",
              " 'slauther': 52093,\n",
              " \"'flame'\": 52094,\n",
              " 'sommerset': 52095,\n",
              " 'interwhined': 52096,\n",
              " 'whacking': 27641,\n",
              " 'bartok': 52097,\n",
              " 'barton': 8778,\n",
              " 'frewer': 21912,\n",
              " \"fi'\": 52098,\n",
              " 'ingrid': 6195,\n",
              " 'stribor': 30578,\n",
              " 'approporiately': 52099,\n",
              " 'wobblyhand': 52100,\n",
              " 'tantalisingly': 52101,\n",
              " 'ankylosaurus': 52102,\n",
              " 'parasites': 17637,\n",
              " 'childen': 52103,\n",
              " \"jenkins'\": 52104,\n",
              " 'metafiction': 52105,\n",
              " 'golem': 17638,\n",
              " 'indiscretion': 40863,\n",
              " \"reeves'\": 23386,\n",
              " \"inamorata's\": 57784,\n",
              " 'brittannica': 52107,\n",
              " 'adapt': 7919,\n",
              " \"russo's\": 30579,\n",
              " 'guitarists': 48249,\n",
              " 'abbott': 10556,\n",
              " 'abbots': 40864,\n",
              " 'lanisha': 17652,\n",
              " 'magickal': 40866,\n",
              " 'mattter': 52108,\n",
              " \"'willy\": 52109,\n",
              " 'pumpkins': 34719,\n",
              " 'stuntpeople': 52110,\n",
              " 'estimate': 30580,\n",
              " 'ugghhh': 40867,\n",
              " 'gameplay': 11312,\n",
              " \"wern't\": 52111,\n",
              " \"n'sync\": 40868,\n",
              " 'sickeningly': 16120,\n",
              " 'chiara': 40869,\n",
              " 'disturbed': 4014,\n",
              " 'portmanteau': 40870,\n",
              " 'ineffectively': 52112,\n",
              " \"duchonvey's\": 82146,\n",
              " \"nasty'\": 37522,\n",
              " 'purpose': 1288,\n",
              " 'lazers': 52115,\n",
              " 'lightened': 28108,\n",
              " 'kaliganj': 52116,\n",
              " 'popularism': 52117,\n",
              " \"damme's\": 18514,\n",
              " 'stylistics': 30581,\n",
              " 'mindgaming': 52118,\n",
              " 'spoilerish': 46452,\n",
              " \"'corny'\": 52120,\n",
              " 'boerner': 34721,\n",
              " 'olds': 6795,\n",
              " 'bakelite': 52121,\n",
              " 'renovated': 27642,\n",
              " 'forrester': 27643,\n",
              " \"lumiere's\": 52122,\n",
              " 'gaskets': 52027,\n",
              " 'needed': 887,\n",
              " 'smight': 34722,\n",
              " 'master': 1300,\n",
              " \"edie's\": 25908,\n",
              " 'seeber': 40871,\n",
              " 'hiya': 52123,\n",
              " 'fuzziness': 52124,\n",
              " 'genesis': 14900,\n",
              " 'rewards': 12610,\n",
              " 'enthrall': 30582,\n",
              " \"'about\": 40872,\n",
              " \"recollection's\": 52125,\n",
              " 'mutilated': 11042,\n",
              " 'fatherlands': 52126,\n",
              " \"fischer's\": 52127,\n",
              " 'positively': 5402,\n",
              " '270': 34708,\n",
              " 'ahmed': 34723,\n",
              " 'zatoichi': 9839,\n",
              " 'bannister': 13889,\n",
              " 'anniversaries': 52130,\n",
              " \"helm's\": 30583,\n",
              " \"'work'\": 52131,\n",
              " 'exclaimed': 34724,\n",
              " \"'unfunny'\": 52132,\n",
              " '274': 52032,\n",
              " 'feeling': 547,\n",
              " \"wanda's\": 52134,\n",
              " 'dolan': 33269,\n",
              " '278': 52136,\n",
              " 'peacoat': 52137,\n",
              " 'brawny': 40873,\n",
              " 'mishra': 40874,\n",
              " 'worlders': 40875,\n",
              " 'protags': 52138,\n",
              " 'skullcap': 52139,\n",
              " 'dastagir': 57599,\n",
              " 'affairs': 5625,\n",
              " 'wholesome': 7802,\n",
              " 'hymen': 52140,\n",
              " 'paramedics': 25249,\n",
              " 'unpersons': 52141,\n",
              " 'heavyarms': 52142,\n",
              " 'affaire': 52143,\n",
              " 'coulisses': 52144,\n",
              " 'hymer': 40876,\n",
              " 'kremlin': 52145,\n",
              " 'shipments': 30584,\n",
              " 'pixilated': 52146,\n",
              " \"'00s\": 30585,\n",
              " 'diminishing': 18515,\n",
              " 'cinematic': 1360,\n",
              " 'resonates': 14901,\n",
              " 'simplify': 40877,\n",
              " \"nature'\": 40878,\n",
              " 'temptresses': 40879,\n",
              " 'reverence': 16825,\n",
              " 'resonated': 19505,\n",
              " 'dailey': 34725,\n",
              " '2\\x85': 52147,\n",
              " 'treize': 27644,\n",
              " 'majo': 52148,\n",
              " 'kiya': 21913,\n",
              " 'woolnough': 52149,\n",
              " 'thanatos': 39800,\n",
              " 'sandoval': 35734,\n",
              " 'dorama': 40882,\n",
              " \"o'shaughnessy\": 52150,\n",
              " 'tech': 4991,\n",
              " 'fugitives': 32021,\n",
              " 'teck': 30586,\n",
              " \"'e'\": 76128,\n",
              " 'doesn’t': 40884,\n",
              " 'purged': 52152,\n",
              " 'saying': 660,\n",
              " \"martians'\": 41098,\n",
              " 'norliss': 23421,\n",
              " 'dickey': 27645,\n",
              " 'dicker': 52155,\n",
              " \"'sependipity\": 52156,\n",
              " 'padded': 8425,\n",
              " 'ordell': 57795,\n",
              " \"sturges'\": 40885,\n",
              " 'independentcritics': 52157,\n",
              " 'tempted': 5748,\n",
              " \"atkinson's\": 34727,\n",
              " 'hounded': 25250,\n",
              " 'apace': 52158,\n",
              " 'clicked': 15497,\n",
              " \"'humor'\": 30587,\n",
              " \"martino's\": 17180,\n",
              " \"'supporting\": 52159,\n",
              " 'warmongering': 52035,\n",
              " \"zemeckis's\": 34728,\n",
              " 'lube': 21914,\n",
              " 'shocky': 52160,\n",
              " 'plate': 7479,\n",
              " 'plata': 40886,\n",
              " 'sturgess': 40887,\n",
              " \"nerds'\": 40888,\n",
              " 'plato': 20603,\n",
              " 'plath': 34729,\n",
              " 'platt': 40889,\n",
              " 'mcnab': 52162,\n",
              " 'clumsiness': 27646,\n",
              " 'altogether': 3902,\n",
              " 'massacring': 42587,\n",
              " 'bicenntinial': 52163,\n",
              " 'skaal': 40890,\n",
              " 'droning': 14363,\n",
              " 'lds': 8779,\n",
              " 'jaguar': 21915,\n",
              " \"cale's\": 34730,\n",
              " 'nicely': 1780,\n",
              " 'mummy': 4591,\n",
              " \"lot's\": 18516,\n",
              " 'patch': 10089,\n",
              " 'kerkhof': 50205,\n",
              " \"leader's\": 52164,\n",
              " \"'movie\": 27647,\n",
              " 'uncomfirmed': 52165,\n",
              " 'heirloom': 40891,\n",
              " 'wrangle': 47363,\n",
              " 'emotion\\x85': 52166,\n",
              " \"'stargate'\": 52167,\n",
              " 'pinoy': 40892,\n",
              " 'conchatta': 40893,\n",
              " 'broeke': 41131,\n",
              " 'advisedly': 40894,\n",
              " \"barker's\": 17639,\n",
              " 'descours': 52169,\n",
              " 'lots': 775,\n",
              " 'lotr': 9262,\n",
              " 'irs': 9882,\n",
              " 'lott': 52170,\n",
              " 'xvi': 40895,\n",
              " 'irk': 34731,\n",
              " 'irl': 52171,\n",
              " 'ira': 6890,\n",
              " 'belzer': 21916,\n",
              " 'irc': 52172,\n",
              " 'ire': 27648,\n",
              " 'requisites': 40896,\n",
              " 'discipline': 7696,\n",
              " 'lyoko': 52964,\n",
              " 'extend': 11313,\n",
              " 'nature': 876,\n",
              " \"'dickie'\": 52173,\n",
              " 'optimist': 40897,\n",
              " 'lapping': 30589,\n",
              " 'superficial': 3903,\n",
              " 'vestment': 52174,\n",
              " 'extent': 2826,\n",
              " 'tendons': 52175,\n",
              " \"heller's\": 52176,\n",
              " 'quagmires': 52177,\n",
              " 'miyako': 52178,\n",
              " 'moocow': 20604,\n",
              " \"coles'\": 52179,\n",
              " 'lookit': 40898,\n",
              " 'ravenously': 52180,\n",
              " 'levitating': 40899,\n",
              " 'perfunctorily': 52181,\n",
              " 'lookin': 30590,\n",
              " \"lot'\": 40901,\n",
              " 'lookie': 52182,\n",
              " 'fearlessly': 34873,\n",
              " 'libyan': 52184,\n",
              " 'fondles': 40902,\n",
              " 'gopher': 35717,\n",
              " 'wearying': 40904,\n",
              " \"nz's\": 52185,\n",
              " 'minuses': 27649,\n",
              " 'puposelessly': 52186,\n",
              " 'shandling': 52187,\n",
              " 'decapitates': 31271,\n",
              " 'humming': 11932,\n",
              " \"'nother\": 40905,\n",
              " 'smackdown': 21917,\n",
              " 'underdone': 30591,\n",
              " 'frf': 40906,\n",
              " 'triviality': 52188,\n",
              " 'fro': 25251,\n",
              " 'bothers': 8780,\n",
              " \"'kensington\": 52189,\n",
              " 'much': 76,\n",
              " 'muco': 34733,\n",
              " 'wiseguy': 22618,\n",
              " \"richie's\": 27651,\n",
              " 'tonino': 40907,\n",
              " 'unleavened': 52190,\n",
              " 'fry': 11590,\n",
              " \"'tv'\": 40908,\n",
              " 'toning': 40909,\n",
              " 'obese': 14364,\n",
              " 'sensationalized': 30592,\n",
              " 'spiv': 40910,\n",
              " 'spit': 6262,\n",
              " 'arkin': 7367,\n",
              " 'charleton': 21918,\n",
              " 'jeon': 16826,\n",
              " 'boardroom': 21919,\n",
              " 'doubts': 4992,\n",
              " 'spin': 3087,\n",
              " 'hepo': 53086,\n",
              " 'wildcat': 27652,\n",
              " 'venoms': 10587,\n",
              " 'misconstrues': 52194,\n",
              " 'mesmerising': 18517,\n",
              " 'misconstrued': 40911,\n",
              " 'rescinds': 52195,\n",
              " 'prostrate': 52196,\n",
              " 'majid': 40912,\n",
              " 'climbed': 16482,\n",
              " 'canoeing': 34734,\n",
              " 'majin': 52198,\n",
              " 'animie': 57807,\n",
              " 'sylke': 40913,\n",
              " 'conditioned': 14902,\n",
              " 'waddell': 40914,\n",
              " '3\\x85': 52199,\n",
              " 'hyperdrive': 41191,\n",
              " 'conditioner': 34735,\n",
              " 'bricklayer': 53156,\n",
              " 'hong': 2579,\n",
              " 'memoriam': 52201,\n",
              " 'inventively': 30595,\n",
              " \"levant's\": 25252,\n",
              " 'portobello': 20641,\n",
              " 'remand': 52203,\n",
              " 'mummified': 19507,\n",
              " 'honk': 27653,\n",
              " 'spews': 19508,\n",
              " 'visitations': 40915,\n",
              " 'mummifies': 52204,\n",
              " 'cavanaugh': 25253,\n",
              " 'zeon': 23388,\n",
              " \"jungle's\": 40916,\n",
              " 'viertel': 34736,\n",
              " 'frenchmen': 27654,\n",
              " 'torpedoes': 52205,\n",
              " 'schlessinger': 52206,\n",
              " 'torpedoed': 34737,\n",
              " 'blister': 69879,\n",
              " 'cinefest': 52207,\n",
              " 'furlough': 34738,\n",
              " 'mainsequence': 52208,\n",
              " 'mentors': 40917,\n",
              " 'academic': 9097,\n",
              " 'stillness': 20605,\n",
              " 'academia': 40918,\n",
              " 'lonelier': 52209,\n",
              " 'nibby': 52210,\n",
              " \"losers'\": 52211,\n",
              " 'cineastes': 40919,\n",
              " 'corporate': 4452,\n",
              " 'massaging': 40920,\n",
              " 'bellow': 30596,\n",
              " 'absurdities': 19509,\n",
              " 'expetations': 53244,\n",
              " 'nyfiken': 40921,\n",
              " 'mehras': 75641,\n",
              " 'lasse': 52212,\n",
              " 'visability': 52213,\n",
              " 'militarily': 33949,\n",
              " \"elder'\": 52214,\n",
              " 'gainsbourg': 19026,\n",
              " 'hah': 20606,\n",
              " 'hai': 13423,\n",
              " 'haj': 34739,\n",
              " 'hak': 25254,\n",
              " 'hal': 4314,\n",
              " 'ham': 4895,\n",
              " 'duffer': 53262,\n",
              " 'haa': 52216,\n",
              " 'had': 69,\n",
              " 'advancement': 11933,\n",
              " 'hag': 16828,\n",
              " \"hand'\": 25255,\n",
              " 'hay': 13424,\n",
              " 'mcnamara': 20607,\n",
              " \"mozart's\": 52217,\n",
              " 'duffel': 30734,\n",
              " 'haq': 30597,\n",
              " 'har': 13890,\n",
              " 'has': 47,\n",
              " 'hat': 2404,\n",
              " 'hav': 40922,\n",
              " 'haw': 30598,\n",
              " 'figtings': 52218,\n",
              " 'elders': 15498,\n",
              " 'underpanted': 52219,\n",
              " 'pninson': 52220,\n",
              " 'unequivocally': 27655,\n",
              " \"barbara's\": 23676,\n",
              " \"bello'\": 52222,\n",
              " 'indicative': 13000,\n",
              " 'yawnfest': 40923,\n",
              " 'hexploitation': 52223,\n",
              " \"loder's\": 52224,\n",
              " 'sleuthing': 27656,\n",
              " \"justin's\": 32625,\n",
              " \"'ball\": 52225,\n",
              " \"'summer\": 52226,\n",
              " \"'demons'\": 34938,\n",
              " \"mormon's\": 52228,\n",
              " \"laughton's\": 34740,\n",
              " 'debell': 52229,\n",
              " 'shipyard': 39727,\n",
              " 'unabashedly': 30600,\n",
              " 'disks': 40404,\n",
              " 'crowd': 2293,\n",
              " 'crowe': 10090,\n",
              " \"vancouver's\": 56437,\n",
              " 'mosques': 34741,\n",
              " 'crown': 6630,\n",
              " 'culpas': 52230,\n",
              " 'crows': 27657,\n",
              " 'surrell': 53347,\n",
              " 'flowless': 52232,\n",
              " 'sheirk': 52233,\n",
              " \"'three\": 40926,\n",
              " \"peterson'\": 52234,\n",
              " 'ooverall': 52235,\n",
              " 'perchance': 40927,\n",
              " 'bottom': 1324,\n",
              " 'chabert': 53366,\n",
              " 'sneha': 52236,\n",
              " 'inhuman': 13891,\n",
              " 'ichii': 52237,\n",
              " 'ursla': 52238,\n",
              " 'completly': 30601,\n",
              " 'moviedom': 40928,\n",
              " 'raddick': 52239,\n",
              " 'brundage': 51998,\n",
              " 'brigades': 40929,\n",
              " 'starring': 1184,\n",
              " \"'goal'\": 52240,\n",
              " 'caskets': 52241,\n",
              " 'willcock': 52242,\n",
              " \"threesome's\": 52243,\n",
              " \"mosque'\": 52244,\n",
              " \"cover's\": 52245,\n",
              " 'spaceships': 17640,\n",
              " 'anomalous': 40930,\n",
              " 'ptsd': 27658,\n",
              " 'shirdan': 52246,\n",
              " 'obscenity': 21965,\n",
              " 'lemmings': 30602,\n",
              " 'duccio': 30603,\n",
              " \"levene's\": 52247,\n",
              " \"'gorby'\": 52248,\n",
              " \"teenager's\": 25258,\n",
              " 'marshall': 5343,\n",
              " 'honeymoon': 9098,\n",
              " 'shoots': 3234,\n",
              " 'despised': 12261,\n",
              " 'okabasho': 52249,\n",
              " 'fabric': 8292,\n",
              " 'cannavale': 18518,\n",
              " 'raped': 3540,\n",
              " \"tutt's\": 52250,\n",
              " 'grasping': 17641,\n",
              " 'despises': 18519,\n",
              " \"thief's\": 40931,\n",
              " 'rapes': 8929,\n",
              " 'raper': 52251,\n",
              " \"eyre'\": 27659,\n",
              " 'walchek': 52252,\n",
              " \"elmo's\": 23389,\n",
              " 'perfumes': 40932,\n",
              " 'spurting': 21921,\n",
              " \"exposition'\\x85\": 52253,\n",
              " 'denoting': 52254,\n",
              " 'thesaurus': 34743,\n",
              " \"shoot'\": 40933,\n",
              " 'bonejack': 49762,\n",
              " 'simpsonian': 52256,\n",
              " 'hebetude': 30604,\n",
              " \"hallow's\": 34744,\n",
              " 'desperation\\x85': 52257,\n",
              " 'incinerator': 34745,\n",
              " 'congratulations': 10311,\n",
              " 'humbled': 52258,\n",
              " \"else's\": 5927,\n",
              " 'trelkovski': 40848,\n",
              " \"rape'\": 52259,\n",
              " \"'chapters'\": 59389,\n",
              " '1600s': 52260,\n",
              " 'martian': 7256,\n",
              " 'nicest': 25259,\n",
              " 'eyred': 52262,\n",
              " 'passenger': 9460,\n",
              " 'disgrace': 6044,\n",
              " 'moderne': 52263,\n",
              " 'barrymore': 5123,\n",
              " 'yankovich': 52264,\n",
              " 'moderns': 40934,\n",
              " 'studliest': 52265,\n",
              " 'bedsheet': 52266,\n",
              " 'decapitation': 14903,\n",
              " 'slurring': 52267,\n",
              " \"'nunsploitation'\": 52268,\n",
              " \"'character'\": 34746,\n",
              " 'cambodia': 9883,\n",
              " 'rebelious': 52269,\n",
              " 'pasadena': 27660,\n",
              " 'crowne': 40935,\n",
              " \"'bedchamber\": 52270,\n",
              " 'conjectural': 52271,\n",
              " 'appologize': 52272,\n",
              " 'halfassing': 52273,\n",
              " 'paycheque': 57819,\n",
              " 'palms': 20609,\n",
              " \"'islands\": 52274,\n",
              " 'hawked': 40936,\n",
              " 'palme': 21922,\n",
              " 'conservatively': 40937,\n",
              " 'larp': 64010,\n",
              " 'palma': 5561,\n",
              " 'smelling': 21923,\n",
              " 'aragorn': 13001,\n",
              " 'hawker': 52275,\n",
              " 'hawkes': 52276,\n",
              " 'explosions': 3978,\n",
              " 'loren': 8062,\n",
              " \"pyle's\": 52277,\n",
              " 'shootout': 6707,\n",
              " \"mike's\": 18520,\n",
              " \"driscoll's\": 52278,\n",
              " 'cogsworth': 40938,\n",
              " \"britian's\": 52279,\n",
              " 'childs': 34747,\n",
              " \"portrait's\": 52280,\n",
              " 'chain': 3629,\n",
              " 'whoever': 2500,\n",
              " 'puttered': 52281,\n",
              " 'childe': 52282,\n",
              " 'maywether': 52283,\n",
              " 'chair': 3039,\n",
              " \"rance's\": 52284,\n",
              " 'machu': 34748,\n",
              " 'ballet': 4520,\n",
              " 'grapples': 34749,\n",
              " 'summerize': 76155,\n",
              " 'freelance': 30606,\n",
              " \"andrea's\": 52286,\n",
              " '\\x91very': 52287,\n",
              " 'coolidge': 45882,\n",
              " 'mache': 18521,\n",
              " 'balled': 52288,\n",
              " 'grappled': 40940,\n",
              " 'macha': 18522,\n",
              " 'underlining': 21924,\n",
              " 'macho': 5626,\n",
              " 'oversight': 19510,\n",
              " 'machi': 25260,\n",
              " 'verbally': 11314,\n",
              " 'tenacious': 21925,\n",
              " 'windshields': 40941,\n",
              " 'paychecks': 18560,\n",
              " 'jerk': 3399,\n",
              " \"good'\": 11934,\n",
              " 'prancer': 34751,\n",
              " 'prances': 21926,\n",
              " 'olympus': 52289,\n",
              " 'lark': 21927,\n",
              " 'embark': 10788,\n",
              " 'gloomy': 7368,\n",
              " 'jehaan': 52290,\n",
              " 'turaqui': 52291,\n",
              " \"child'\": 20610,\n",
              " 'locked': 2897,\n",
              " 'pranced': 52292,\n",
              " 'exact': 2591,\n",
              " 'unattuned': 52293,\n",
              " 'minute': 786,\n",
              " 'skewed': 16121,\n",
              " 'hodgins': 40943,\n",
              " 'skewer': 34752,\n",
              " 'think\\x85': 52294,\n",
              " 'rosenstein': 38768,\n",
              " 'helmit': 52295,\n",
              " 'wrestlemanias': 34753,\n",
              " 'hindered': 16829,\n",
              " \"martha's\": 30607,\n",
              " 'cheree': 52296,\n",
              " \"pluckin'\": 52297,\n",
              " 'ogles': 40944,\n",
              " 'heavyweight': 11935,\n",
              " 'aada': 82193,\n",
              " 'chopping': 11315,\n",
              " 'strongboy': 61537,\n",
              " 'hegemonic': 41345,\n",
              " 'adorns': 40945,\n",
              " 'xxth': 41349,\n",
              " 'nobuhiro': 34754,\n",
              " 'capitães': 52301,\n",
              " 'kavogianni': 52302,\n",
              " 'antwerp': 13425,\n",
              " 'celebrated': 6541,\n",
              " 'roarke': 52303,\n",
              " 'baggins': 40946,\n",
              " 'cheeseburgers': 31273,\n",
              " 'matras': 52304,\n",
              " \"nineties'\": 52305,\n",
              " \"'craig'\": 52306,\n",
              " 'celebrates': 13002,\n",
              " 'unintentionally': 3386,\n",
              " 'drafted': 14365,\n",
              " 'climby': 52307,\n",
              " '303': 52308,\n",
              " 'oldies': 18523,\n",
              " 'climbs': 9099,\n",
              " 'honour': 9658,\n",
              " 'plucking': 34755,\n",
              " '305': 30077,\n",
              " 'address': 5517,\n",
              " 'menjou': 40947,\n",
              " \"'freak'\": 42595,\n",
              " 'dwindling': 19511,\n",
              " 'benson': 9461,\n",
              " 'white’s': 52310,\n",
              " 'shamelessness': 40948,\n",
              " 'impacted': 21928,\n",
              " 'upatz': 52311,\n",
              " 'cusack': 3843,\n",
              " \"flavia's\": 37570,\n",
              " 'effette': 52312,\n",
              " 'influx': 34756,\n",
              " 'boooooooo': 52313,\n",
              " 'dimitrova': 52314,\n",
              " 'houseman': 13426,\n",
              " 'bigas': 25262,\n",
              " 'boylen': 52315,\n",
              " 'phillipenes': 52316,\n",
              " 'fakery': 40949,\n",
              " \"grandpa's\": 27661,\n",
              " 'darnell': 27662,\n",
              " 'undergone': 19512,\n",
              " 'handbags': 52318,\n",
              " 'perished': 21929,\n",
              " 'pooped': 37781,\n",
              " 'vigour': 27663,\n",
              " 'opposed': 3630,\n",
              " 'etude': 52319,\n",
              " \"caine's\": 11802,\n",
              " 'doozers': 52320,\n",
              " 'photojournals': 34757,\n",
              " 'perishes': 52321,\n",
              " 'constrains': 34758,\n",
              " 'migenes': 40951,\n",
              " 'consoled': 30608,\n",
              " 'alastair': 16830,\n",
              " 'wvs': 52322,\n",
              " 'ooooooh': 52323,\n",
              " 'approving': 34759,\n",
              " 'consoles': 40952,\n",
              " 'disparagement': 52067,\n",
              " 'futureistic': 52325,\n",
              " 'rebounding': 52326,\n",
              " \"'date\": 52327,\n",
              " 'gregoire': 52328,\n",
              " 'rutherford': 21930,\n",
              " 'americanised': 34760,\n",
              " 'novikov': 82199,\n",
              " 'following': 1045,\n",
              " 'munroe': 34761,\n",
              " \"morita'\": 52329,\n",
              " 'christenssen': 52330,\n",
              " 'oatmeal': 23109,\n",
              " 'fossey': 25263,\n",
              " 'livered': 40953,\n",
              " 'listens': 13003,\n",
              " \"'marci\": 76167,\n",
              " \"otis's\": 52333,\n",
              " 'thanking': 23390,\n",
              " 'maude': 16022,\n",
              " 'extensions': 34762,\n",
              " 'ameteurish': 52335,\n",
              " \"commender's\": 52336,\n",
              " 'agricultural': 27664,\n",
              " 'convincingly': 4521,\n",
              " 'fueled': 17642,\n",
              " 'mahattan': 54017,\n",
              " \"paris's\": 40955,\n",
              " 'vulkan': 52339,\n",
              " 'stapes': 52340,\n",
              " 'odysessy': 52341,\n",
              " 'harmon': 12262,\n",
              " 'surfing': 4255,\n",
              " 'halloran': 23497,\n",
              " 'unbelieveably': 49583,\n",
              " \"'offed'\": 52342,\n",
              " 'quadrant': 30610,\n",
              " 'inhabiting': 19513,\n",
              " 'nebbish': 34763,\n",
              " 'forebears': 40956,\n",
              " 'skirmish': 34764,\n",
              " 'ocassionally': 52343,\n",
              " \"'resist\": 52344,\n",
              " 'impactful': 21931,\n",
              " 'spicier': 52345,\n",
              " 'touristy': 40957,\n",
              " \"'football'\": 52346,\n",
              " 'webpage': 40958,\n",
              " 'exurbia': 52348,\n",
              " 'jucier': 52349,\n",
              " 'professors': 14904,\n",
              " 'structuring': 34765,\n",
              " 'jig': 30611,\n",
              " 'overlord': 40959,\n",
              " 'disconnect': 25264,\n",
              " 'sniffle': 82204,\n",
              " 'slimeball': 40960,\n",
              " 'jia': 40961,\n",
              " 'milked': 16831,\n",
              " 'banjoes': 40962,\n",
              " 'jim': 1240,\n",
              " 'workforces': 52351,\n",
              " 'jip': 52352,\n",
              " 'rotweiller': 52353,\n",
              " 'mundaneness': 34766,\n",
              " \"'ninja'\": 52354,\n",
              " \"dead'\": 11043,\n",
              " \"cipriani's\": 40963,\n",
              " 'modestly': 20611,\n",
              " \"professor'\": 52355,\n",
              " 'shacked': 40964,\n",
              " 'bashful': 34767,\n",
              " 'sorter': 23391,\n",
              " 'overpowering': 16123,\n",
              " 'workmanlike': 18524,\n",
              " 'henpecked': 27665,\n",
              " 'sorted': 18525,\n",
              " \"jōb's\": 52357,\n",
              " \"'always\": 52358,\n",
              " \"'baptists\": 34768,\n",
              " 'dreamcatchers': 52359,\n",
              " \"'silence'\": 52360,\n",
              " 'hickory': 21932,\n",
              " 'fun\\x97yet': 52361,\n",
              " 'breakumentary': 52362,\n",
              " 'didn': 15499,\n",
              " 'didi': 52363,\n",
              " 'pealing': 52364,\n",
              " 'dispite': 40965,\n",
              " \"italy's\": 25265,\n",
              " 'instability': 21933,\n",
              " 'quarter': 6542,\n",
              " 'quartet': 12611,\n",
              " 'padmé': 52365,\n",
              " \"'bleedmedry\": 52366,\n",
              " 'pahalniuk': 52367,\n",
              " 'honduras': 52368,\n",
              " 'bursting': 10789,\n",
              " \"pablo's\": 41468,\n",
              " 'irremediably': 52370,\n",
              " 'presages': 40966,\n",
              " 'bowlegged': 57835,\n",
              " 'dalip': 65186,\n",
              " 'entering': 6263,\n",
              " 'newsradio': 76175,\n",
              " 'presaged': 54153,\n",
              " \"giallo's\": 27666,\n",
              " 'bouyant': 40967,\n",
              " 'amerterish': 52371,\n",
              " 'rajni': 18526,\n",
              " 'leeves': 30613,\n",
              " 'macauley': 34770,\n",
              " 'seriously': 615,\n",
              " 'sugercoma': 52372,\n",
              " 'grimstead': 52373,\n",
              " \"'fairy'\": 52374,\n",
              " 'zenda': 30614,\n",
              " \"'twins'\": 52375,\n",
              " 'realisation': 17643,\n",
              " 'highsmith': 27667,\n",
              " 'raunchy': 7820,\n",
              " 'incentives': 40968,\n",
              " 'flatson': 52377,\n",
              " 'snooker': 35100,\n",
              " 'crazies': 16832,\n",
              " 'crazier': 14905,\n",
              " 'grandma': 7097,\n",
              " 'napunsaktha': 52378,\n",
              " 'workmanship': 30615,\n",
              " 'reisner': 52379,\n",
              " \"sanford's\": 61309,\n",
              " '\\x91doña': 52380,\n",
              " 'modest': 6111,\n",
              " \"everything's\": 19156,\n",
              " 'hamer': 40969,\n",
              " \"couldn't'\": 52382,\n",
              " 'quibble': 13004,\n",
              " 'socking': 52383,\n",
              " 'tingler': 21934,\n",
              " 'gutman': 52384,\n",
              " 'lachlan': 40970,\n",
              " 'tableaus': 52385,\n",
              " 'headbanger': 52386,\n",
              " 'spoken': 2850,\n",
              " 'cerebrally': 34771,\n",
              " \"'road\": 23493,\n",
              " 'tableaux': 21935,\n",
              " \"proust's\": 40971,\n",
              " 'periodical': 40972,\n",
              " \"shoveller's\": 52388,\n",
              " 'tamara': 25266,\n",
              " 'affords': 17644,\n",
              " 'concert': 3252,\n",
              " \"yara's\": 87958,\n",
              " 'someome': 52389,\n",
              " 'lingering': 8427,\n",
              " \"abraham's\": 41514,\n",
              " 'beesley': 34772,\n",
              " 'cherbourg': 34773,\n",
              " 'kagan': 28627,\n",
              " 'snatch': 9100,\n",
              " \"miyazaki's\": 9263,\n",
              " 'absorbs': 25267,\n",
              " \"koltai's\": 40973,\n",
              " 'tingled': 64030,\n",
              " 'crossroads': 19514,\n",
              " 'rehab': 16124,\n",
              " 'falworth': 52392,\n",
              " 'sequals': 52393,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imQwc84Gd5mN"
      },
      "source": [
        "**Zadanie 0. Stwórz odwrotność powyższego słownika, by móc odczytywać recenzje**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rf0oAd3A8Jku"
      },
      "outputs": [],
      "source": [
        "index_word = {v:k for k,v in word_index.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRFUrNGLd5mO"
      },
      "source": [
        "#### Odczytajmy pierwszą z recenzji, indeksowo, a potem słownie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0M-Fkb9z8Jk0",
        "outputId": "870bac81-a133-4dd5-a908-d2256bb0ecb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 2,\n",
              " 173,\n",
              " 2,\n",
              " 256,\n",
              " 2,\n",
              " 2,\n",
              " 100,\n",
              " 2,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 480,\n",
              " 284,\n",
              " 2,\n",
              " 150,\n",
              " 2,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 2,\n",
              " 2,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 2,\n",
              " 546,\n",
              " 2,\n",
              " 2,\n",
              " 447,\n",
              " 2,\n",
              " 192,\n",
              " 50,\n",
              " 2,\n",
              " 2,\n",
              " 147,\n",
              " 2025,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 2,\n",
              " 2,\n",
              " 71,\n",
              " 87,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 530,\n",
              " 2,\n",
              " 76,\n",
              " 2,\n",
              " 2,\n",
              " 1247,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 515,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 626,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 62,\n",
              " 386,\n",
              " 2,\n",
              " 2,\n",
              " 316,\n",
              " 2,\n",
              " 106,\n",
              " 2,\n",
              " 2,\n",
              " 2223,\n",
              " 2,\n",
              " 2,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 2,\n",
              " 2,\n",
              " 130,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 619,\n",
              " 2,\n",
              " 2,\n",
              " 124,\n",
              " 51,\n",
              " 2,\n",
              " 135,\n",
              " 2,\n",
              " 2,\n",
              " 1415,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 215,\n",
              " 2,\n",
              " 77,\n",
              " 52,\n",
              " 2,\n",
              " 2,\n",
              " 407,\n",
              " 2,\n",
              " 82,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 107,\n",
              " 117,\n",
              " 2,\n",
              " 2,\n",
              " 256,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3766,\n",
              " 2,\n",
              " 723,\n",
              " 2,\n",
              " 71,\n",
              " 2,\n",
              " 530,\n",
              " 476,\n",
              " 2,\n",
              " 400,\n",
              " 317,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1029,\n",
              " 2,\n",
              " 104,\n",
              " 88,\n",
              " 2,\n",
              " 381,\n",
              " 2,\n",
              " 297,\n",
              " 98,\n",
              " 2,\n",
              " 2071,\n",
              " 56,\n",
              " 2,\n",
              " 141,\n",
              " 2,\n",
              " 194,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 226,\n",
              " 2,\n",
              " 2,\n",
              " 134,\n",
              " 476,\n",
              " 2,\n",
              " 480,\n",
              " 2,\n",
              " 144,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 51,\n",
              " 2,\n",
              " 2,\n",
              " 224,\n",
              " 92,\n",
              " 2,\n",
              " 104,\n",
              " 2,\n",
              " 226,\n",
              " 65,\n",
              " 2,\n",
              " 2,\n",
              " 1334,\n",
              " 88,\n",
              " 2,\n",
              " 2,\n",
              " 283,\n",
              " 2,\n",
              " 2,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 178,\n",
              " 2]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "suwAxmI18Jk4",
        "outputId": "6e82658f-83d9-43ce-dd23-690608b792c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"UNK UNK UNK UNK UNK brilliant casting location scenery story direction everyone's really suited UNK part UNK played UNK UNK could UNK imagine being there robert UNK UNK UNK amazing actor UNK now UNK same being director UNK father came UNK UNK same scottish island UNK myself UNK UNK loved UNK fact there UNK UNK real connection UNK UNK UNK UNK witty remarks throughout UNK UNK were great UNK UNK UNK brilliant UNK much UNK UNK bought UNK UNK UNK soon UNK UNK UNK released UNK UNK UNK would recommend UNK UNK everyone UNK watch UNK UNK fly UNK UNK amazing really cried UNK UNK end UNK UNK UNK sad UNK UNK know what UNK say UNK UNK cry UNK UNK UNK UNK must UNK been good UNK UNK definitely UNK also UNK UNK UNK two little UNK UNK played UNK UNK UNK norman UNK paul UNK were UNK brilliant children UNK often left UNK UNK UNK UNK list UNK think because UNK stars UNK play them UNK grown up UNK such UNK big UNK UNK UNK whole UNK UNK these children UNK amazing UNK should UNK UNK UNK what UNK UNK done don't UNK think UNK whole story UNK UNK lovely because UNK UNK true UNK UNK someone's life after UNK UNK UNK UNK UNK us UNK\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "' '.join(index_word[id] for id in x_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUpPW6wkd5mO"
      },
      "source": [
        "#### Porównajmy sobie to z oryginalną recenzją. W tym celu załadujemy pełną bazę danych recenzji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iI0B124c8Jk8"
      },
      "outputs": [],
      "source": [
        "(all_x_train,_),(all_x_valid,_) = imdb.load_data() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "eKO_1DfM8JlC",
        "outputId": "50747c8a-b738-433e-881a-52e9196501fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"START this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "' '.join(index_word[id] for id in all_x_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWq3ipbu8JlG"
      },
      "source": [
        "#### Przetwórzmy dane poprzez ujednolicenie wielkości danych wejściowych (dopełnienie albo przycięcie)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pT4MXfQe8JlI"
      },
      "outputs": [],
      "source": [
        "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
        "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2EZoIBm28JlL",
        "scrolled": true,
        "outputId": "1ac85b1e-1076-478b-c1fd-c5f1140aee93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1415,    2,    2,    2,    2,  215,    2,   77,   52,    2,    2,\n",
              "         407,    2,   82,    2,    2,    2,  107,  117,    2,    2,  256,\n",
              "           2,    2,    2, 3766,    2,  723,    2,   71,    2,  530,  476,\n",
              "           2,  400,  317,    2,    2,    2,    2, 1029,    2,  104,   88,\n",
              "           2,  381,    2,  297,   98,    2, 2071,   56,    2,  141,    2,\n",
              "         194,    2,    2,    2,  226,    2,    2,  134,  476,    2,  480,\n",
              "           2,  144,    2,    2,    2,   51,    2,    2,  224,   92,    2,\n",
              "         104,    2,  226,   65,    2,    2, 1334,   88,    2,    2,  283,\n",
              "           2,    2, 4472,  113,  103,    2,    2,    2,    2,    2,  178,\n",
              "           2],\n",
              "       [ 163,    2, 3215,    2,    2, 1153,    2,  194,  775,    2,    2,\n",
              "           2,  349, 2637,  148,  605,    2,    2,    2,  123,  125,   68,\n",
              "           2,    2,    2,  349,  165, 4362,   98,    2,    2,  228,    2,\n",
              "           2,    2, 1157,    2,  299,  120,    2,  120,  174,    2,  220,\n",
              "         175,  136,   50,    2, 4373,  228,    2,    2,    2,  656,  245,\n",
              "        2350,    2,    2,    2,  131,  152,  491,    2,    2,    2,    2,\n",
              "        1212,    2,    2,    2,  371,   78,    2,  625,   64, 1382,    2,\n",
              "           2,  168,  145,    2,    2, 1690,    2,    2,    2, 1355,    2,\n",
              "           2,    2,   52,  154,  462,    2,   89,   78,  285,    2,  145,\n",
              "          95],\n",
              "       [1301,    2, 1873,    2,   89,   78,    2,   66,    2,    2,  360,\n",
              "           2,    2,   58,  316,  334,    2,    2, 1716,    2,  645,  662,\n",
              "           2,  257,   85, 1200,    2, 1228, 2578,   83,   68, 3912,    2,\n",
              "           2,  165, 1539,  278,    2,   69,    2,  780,    2,  106,    2,\n",
              "           2, 1338,    2,    2,    2,    2,  215,    2,  610,    2,    2,\n",
              "          87,  326,    2, 2300,    2,    2,    2,    2,  272,    2,   57,\n",
              "           2,    2,    2,    2,    2,    2, 2307,   51,    2,  170,    2,\n",
              "         595,  116,  595, 1352,    2,  191,   79,  638,   89,    2,    2,\n",
              "           2,    2,  106,  607,  624,    2,  534,    2,  227,    2,  129,\n",
              "         113],\n",
              "       [   2,    2,    2,  188, 1076, 3222,    2,    2,    2,    2, 2348,\n",
              "         537,    2,   53,  537,    2,   82,    2,    2,    2,    2,    2,\n",
              "         280,    2,  219,    2,    2,  431,  758,  859,    2,  953, 1052,\n",
              "           2,    2,    2,    2,   94,    2,    2,  238,   60,    2,    2,\n",
              "           2,  804,    2,    2,    2,    2,  132,    2,   67,    2,    2,\n",
              "           2,    2,  283,    2,    2,    2,    2,    2,  242,  955,    2,\n",
              "           2,  279,    2,    2,    2, 1685,  195,    2,  238,   60,  796,\n",
              "           2,    2,  671,    2, 2804,    2,    2,  559,  154,  888,    2,\n",
              "         726,   50,    2,    2,    2,    2,  566,    2,  579,    2,   64,\n",
              "        2574],\n",
              "       [   2,    2,  131, 2073,  249,  114,  249,  229,  249,    2,    2,\n",
              "           2,  126,  110,    2,  473,    2,  569,   61,  419,   56,  429,\n",
              "           2, 1513,    2,    2,  534,   95,  474,  570,    2,    2,  124,\n",
              "         138,   88,    2,  421, 1543,   52,  725,    2,   61,  419,    2,\n",
              "           2, 1571,    2, 1543,    2,    2,    2,    2,    2,  296,    2,\n",
              "        3524,    2,    2,  421,  128,   74,  233,  334,  207,  126,  224,\n",
              "           2,  562,  298, 2167, 1272,    2, 2601,    2,  516,  988,    2,\n",
              "           2,   79,  120,    2,  595,    2,  784,    2, 3171,    2,  165,\n",
              "         170,  143,    2,    2,    2,    2,    2,  226,  251,    2,   61,\n",
              "         113],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    2,  778,  128,   74,    2,  630,  163,    2,    2,\n",
              "        1766,    2, 1051,    2,    2,   85,  156,    2,    2,  148,  139,\n",
              "         121,  664,  665,    2,    2, 1361,  173,    2,  749,    2,    2,\n",
              "        3804,    2,    2,  226,   65,    2,    2,  127,    2,    2,    2,\n",
              "           2]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x_train[0:6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZlYrhHAd5mP"
      },
      "source": [
        "#### Sprawdźmy czy to się udało i jak w praktyce wygląda to ujednolicenie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgfOmHZg8JlQ",
        "outputId": "7275c588-be5f-46a6-ba61-a8311950a7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "for x in x_train[0:6]:\n",
        "    print(len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "PHLZZKWF8JlU",
        "outputId": "d8813649-4618-48b9-b8b2-4b3bb3de65f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"cry UNK UNK UNK UNK must UNK been good UNK UNK definitely UNK also UNK UNK UNK two little UNK UNK played UNK UNK UNK norman UNK paul UNK were UNK brilliant children UNK often left UNK UNK UNK UNK list UNK think because UNK stars UNK play them UNK grown up UNK such UNK big UNK UNK UNK whole UNK UNK these children UNK amazing UNK should UNK UNK UNK what UNK UNK done don't UNK think UNK whole story UNK UNK lovely because UNK UNK true UNK UNK someone's life after UNK UNK UNK UNK UNK us UNK\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "' '.join(index_word[id] for id in x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "nHvfzuZ38JlX",
        "outputId": "a17ac1c9-b30e-404a-e567-e78f576d9b28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD UNK begins better than UNK ends funny UNK UNK russian UNK crew UNK UNK other actors UNK UNK those scenes where documentary shots UNK UNK spoiler part UNK message UNK UNK contrary UNK UNK whole story UNK UNK does UNK UNK UNK UNK'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "' '.join(index_word[id] for id in x_train[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "GscSnCpk8Jlm"
      },
      "source": [
        "#### Zaprojektujmy sieć jednokierunkową do przetworzenia recenzji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg5sZX_Xd5mQ"
      },
      "source": [
        "**Zadanie 1.  Zaprojektuj sieć o następujących warstwach:**\n",
        "\n",
        "    - embedding, z liczbą unikalnych słów, liczbą wymiarów przestrzeni wektorów i maksymalną długością recenzji jako parametrami (sprawdź w dokumentacji tf)\n",
        "    - warstwa spłaszczająca\n",
        "    - dwie warstwy gęste ReLU z dodanymi odpowiednio dropoutami\n",
        "    - warstwę klasyfikującą recenzje na pozytywną i negatywną"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "LyReiequ8Jln"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(n_unique_words, n_dim, input_length=max_review_length),\n",
        "    Flatten(),\n",
        "    Dense(n_dense, activation='relu'),\n",
        "    Dropout(dropout),\n",
        "    Dense(n_dense, activation='relu'),\n",
        "    Dropout(dropout),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nx7eGkg8Jlr",
        "outputId": "b7f68928-e56a-4cc1-bb9b-b88e87d8b406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 64)           320000    \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                409664    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 733,889\n",
            "Trainable params: 733,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sC8mS2Rd5mR"
      },
      "source": [
        "**Zadanie 2. Z czego wynikają liczby parametrów warstwy embedding i pierwszej warstwy gęstej?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL7IWYbKd5mR"
      },
      "source": [
        "Parametry warstwy embedding wynikają z liczby unikalnych słów w zbiorze, wielkości przestrzeni wektorów na wyjściu jaką chcemy uzyskać, maksymalnej długosći recenzji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkbhJMox8Jl9"
      },
      "source": [
        "#### Skonfigurujmy model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBqG7rkgd5mR"
      },
      "source": [
        "**Zadanie 3. Skompiluj model z odpowiednimi dla tego problemu funkcją kosztu i metryką oraz dowolnym optymalizatorem**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QodbQvQh8Jl_"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj9FOlX0d5mR"
      },
      "source": [
        "#### Stwórzmy obiekt i katalog do rejestrowania wag modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "zHjvYe288JmE"
      },
      "outputs": [],
      "source": [
        "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEYpX7968JmL"
      },
      "source": [
        "**Zadanie 4. Naucz sieć na zbiorze treningowym z wyznaczonymi na wstępie hiperparametrami, ze zbiorem walidacyjnym, z użyciem rejestratora wag (sprawdź w dokumentacji tf)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "QaD1W7Ka8JmM",
        "outputId": "712e3e19-fe99-4d03-8dfd-385490b3cabb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "49/49 [==============================] - 2s 22ms/step - loss: 0.6933 - accuracy: 0.5078 - val_loss: 0.6910 - val_accuracy: 0.5861\n",
            "Epoch 2/20\n",
            "49/49 [==============================] - 1s 17ms/step - loss: 0.6205 - accuracy: 0.6671 - val_loss: 0.3983 - val_accuracy: 0.8263\n",
            "Epoch 3/20\n",
            "49/49 [==============================] - 1s 17ms/step - loss: 0.3314 - accuracy: 0.8693 - val_loss: 0.3415 - val_accuracy: 0.8479\n",
            "Epoch 4/20\n",
            "49/49 [==============================] - 1s 14ms/step - loss: 0.1863 - accuracy: 0.9376 - val_loss: 0.4115 - val_accuracy: 0.8337\n",
            "Epoch 5/20\n",
            "49/49 [==============================] - 1s 14ms/step - loss: 0.0677 - accuracy: 0.9817 - val_loss: 0.5472 - val_accuracy: 0.8286\n",
            "Epoch 6/20\n",
            "49/49 [==============================] - 1s 17ms/step - loss: 0.0200 - accuracy: 0.9961 - val_loss: 0.7176 - val_accuracy: 0.8278\n",
            "Epoch 7/20\n",
            "49/49 [==============================] - 1s 17ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.8260 - val_accuracy: 0.8283\n",
            "Epoch 8/20\n",
            "49/49 [==============================] - 1s 17ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.9112 - val_accuracy: 0.8274\n",
            "Epoch 9/20\n",
            "49/49 [==============================] - 1s 14ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.9761 - val_accuracy: 0.8274\n",
            "Epoch 10/20\n",
            "49/49 [==============================] - 1s 14ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 1.0100 - val_accuracy: 0.8301\n",
            "Epoch 11/20\n",
            "49/49 [==============================] - 1s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0510 - val_accuracy: 0.8299\n",
            "Epoch 12/20\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 1.0649 - val_accuracy: 0.8307\n",
            "Epoch 13/20\n",
            "49/49 [==============================] - 1s 14ms/step - loss: 7.2315e-04 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.8306\n",
            "Epoch 14/20\n",
            "49/49 [==============================] - 1s 20ms/step - loss: 8.6902e-04 - accuracy: 0.9998 - val_loss: 1.1448 - val_accuracy: 0.8298\n",
            "Epoch 15/20\n",
            "49/49 [==============================] - 1s 25ms/step - loss: 7.1504e-04 - accuracy: 0.9999 - val_loss: 1.1524 - val_accuracy: 0.8298\n",
            "Epoch 16/20\n",
            "49/49 [==============================] - 1s 27ms/step - loss: 6.4778e-04 - accuracy: 0.9999 - val_loss: 1.1884 - val_accuracy: 0.8294\n",
            "Epoch 17/20\n",
            "49/49 [==============================] - 1s 26ms/step - loss: 5.6152e-04 - accuracy: 0.9999 - val_loss: 1.2115 - val_accuracy: 0.8293\n",
            "Epoch 18/20\n",
            "49/49 [==============================] - 1s 24ms/step - loss: 3.5307e-04 - accuracy: 1.0000 - val_loss: 1.2427 - val_accuracy: 0.8292\n",
            "Epoch 19/20\n",
            "49/49 [==============================] - 1s 24ms/step - loss: 3.4948e-04 - accuracy: 0.9999 - val_loss: 1.2754 - val_accuracy: 0.8283\n",
            "Epoch 20/20\n",
            "49/49 [==============================] - 1s 25ms/step - loss: 2.4635e-04 - accuracy: 1.0000 - val_loss: 1.3005 - val_accuracy: 0.8277\n"
          ]
        }
      ],
      "source": [
        "\n",
        "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PWlH5SJ8JmP"
      },
      "source": [
        "**Zadanie 5. Załaduj wagi z ostatniej epoki (sprawdź w dokumentacji tf) i dokonaj ewaluacji (inferecji) modelu na zbiorze walidacyjnym**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "z8t0nVCw8JmP"
      },
      "outputs": [],
      "source": [
        "model.load_weights(output_dir+f\"/weights.{epochs}.hdf5\".format(epoch=epochs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "kZwGk5dR8JmS"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "EPc5_h6K8JmW",
        "outputId": "cb8ba5b9-b1ac-4344-c36e-bb6fe272977d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "len(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "E_GNq-R_8JmZ",
        "outputId": "e0d5c1a9-8679-4320-dfcf-5f6d5e1d37bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.95765e-06], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "y_pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "SFqRQ5XB8Jmc",
        "outputId": "78822864-d7df-4c4a-df61-4123034d35ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "y_valid[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTF-GI2Id5mT"
      },
      "source": [
        "#### Wyświetlmy histogram dla danych walidacyjnych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "FTWf6Cf-8Jme",
        "outputId": "6087d3b3-b104-4ec9-9442-3474c85c6c49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.hist(y_pred)\n",
        "_ = plt.axvline(x=0.5, color='orange')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC9JK5g8d5mT"
      },
      "source": [
        "Co widzimy? Model jest najczęściej bardzo zdecydowany, większość wartości znajduje się w skrajnych częściach wykresu. Pomarańczowa linia oznacza próg 0.5, powyżej którego model po prostu ocenia recenzję jako pozytywną. Spróbujmy jeszcze zatem na różne sposoby zbadać skuteczność klasyfikacji binarnej."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "RNljSx3v8Jmh",
        "outputId": "4af92cf5-e88b-4f1e-a457-07699af8921f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91.26449855999998"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "roc_auc_score(y_valid, y_pred)*100.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_Rm5HLlMd5mT",
        "outputId": "088173fb-ac93-491f-91ef-7d00cfa10284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_valid, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='Model')\n",
        "display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFqiLVPMd5mT"
      },
      "source": [
        "Krzywa roc wizualizuje zależność między skutecznością klasyfikacją próbek pozytywnych a nietrafnością klasyfikacji przypadków negatywnych (np. podział klientów banku na spłacających i niespłacających kredyty) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_bu_6Hhd5mU"
      },
      "source": [
        "#### Zgromadźmy wyniki, np. w postaci DataFrame'a,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Op2bIcuSd5mU",
        "outputId": "0b45cdfa-a491-46c2-b236-f43ce9169e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         y_pred  y\n",
              "0  9.957650e-06  0\n",
              "1  1.000000e+00  1\n",
              "2  9.999931e-01  1\n",
              "3  9.335317e-02  0\n",
              "4  1.000000e+00  1\n",
              "5  1.556062e-01  1\n",
              "6  9.999931e-01  1\n",
              "7  6.992624e-09  0\n",
              "8  9.999763e-01  0\n",
              "9  9.999990e-01  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f02ccca-f8e9-4b66-997c-78fcf7509b6d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_pred</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.957650e-06</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.999931e-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.335317e-02</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.556062e-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9.999931e-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6.992624e-09</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9.999763e-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9.999990e-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f02ccca-f8e9-4b66-997c-78fcf7509b6d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f02ccca-f8e9-4b66-997c-78fcf7509b6d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f02ccca-f8e9-4b66-997c-78fcf7509b6d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "float_y_pred = []\n",
        "for y in y_pred:\n",
        "    float_y_pred.append(y[0])\n",
        "ydf = pd.DataFrame(list(zip(float_y_pred, y_valid)), columns=['y_pred', 'y'])\n",
        "ydf.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxLlRaXrd5mU"
      },
      "source": [
        "**Zadanie 6. Wyświetl tę recenzję, która została błędnie zaklasyfikowana z największą nieprawidłową pewnością modelu (zauważ i weź pod uwagę, że jeśli wartość prawdopodobieństwa jest bardzo mała, to model również ma dużą pewność - że recenzja jest negatywna)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "2RChijcF8JnA",
        "outputId": "5078770e-07a0-46b7-da01-dfb41a6ec59c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             y_pred  y\n",
              "1059   1.000000e+00  0\n",
              "11496  1.000000e+00  0\n",
              "5795   1.000000e+00  0\n",
              "14246  1.000000e+00  0\n",
              "17502  1.000000e+00  0\n",
              "...             ... ..\n",
              "18710  6.814456e-19  0\n",
              "18828  4.788920e-19  0\n",
              "23585  1.829181e-19  0\n",
              "2904   1.829181e-19  0\n",
              "2624   1.368447e-19  0\n",
              "\n",
              "[12500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12fb1316-3136-4fe2-b7e1-d305e83b1087\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_pred</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1059</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11496</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5795</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14246</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17502</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18710</th>\n",
              "      <td>6.814456e-19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18828</th>\n",
              "      <td>4.788920e-19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23585</th>\n",
              "      <td>1.829181e-19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2904</th>\n",
              "      <td>1.829181e-19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2624</th>\n",
              "      <td>1.368447e-19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12500 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12fb1316-3136-4fe2-b7e1-d305e83b1087')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12fb1316-3136-4fe2-b7e1-d305e83b1087 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12fb1316-3136-4fe2-b7e1-d305e83b1087');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "ydf[ydf['y']==0].sort_values(by='y_pred', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ydf[ydf['y']==1].sort_values(by='y_pred')"
      ],
      "metadata": {
        "id": "uw3jMELA8qgg",
        "outputId": "4b487d4c-c8fd-41c6-d5ed-986414730bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             y_pred  y\n",
              "12612  7.888051e-16  1\n",
              "10184  2.508487e-11  1\n",
              "6185   4.610049e-11  1\n",
              "9221   1.052025e-10  1\n",
              "3699   1.245891e-10  1\n",
              "...             ... ..\n",
              "17336  1.000000e+00  1\n",
              "17328  1.000000e+00  1\n",
              "6064   1.000000e+00  1\n",
              "17348  1.000000e+00  1\n",
              "1      1.000000e+00  1\n",
              "\n",
              "[12500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22420ab4-c45c-4203-abd6-bb646d0d289e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_pred</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12612</th>\n",
              "      <td>7.888051e-16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10184</th>\n",
              "      <td>2.508487e-11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6185</th>\n",
              "      <td>4.610049e-11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9221</th>\n",
              "      <td>1.052025e-10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3699</th>\n",
              "      <td>1.245891e-10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17336</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17328</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6064</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17348</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12500 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22420ab4-c45c-4203-abd6-bb646d0d289e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22420ab4-c45c-4203-abd6-bb646d0d289e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22420ab4-c45c-4203-abd6-bb646d0d289e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dense_sentiment_classifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}